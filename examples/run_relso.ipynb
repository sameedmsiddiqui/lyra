{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488659f8-8391-49e9-9249-ea3b7528c0dd",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53899e6e-1ec7-45c3-a908-d605534b4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (25.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1e2082-e05c-47b3-a219-79ced2d6d9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (8.3.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.15.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (19.0.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.1.3)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (23.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.5.0)\n",
      "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install einops pandas pytest tqdm scipy pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8338d8f-5690-4517-b098-71f8bc74a4bd",
   "metadata": {},
   "source": [
    "## Flash-FFT-Conv\n",
    "\n",
    "It's recommended to restart the kernel after installing FlashFFTConv to ensure successful installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0803d276-c810-42a9-bd7e-481eea9cd51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'flash-fft-conv' already exists and is not an empty directory.\n",
      "/workspace/l2/lyra/examples/flash-fft-conv\n",
      "/workspace/l2/lyra/examples/flash-fft-conv/csrc/flashfftconv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found arch: sm_90 from existing torch installation\n",
      "running install\n",
      "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing monarch_cuda.egg-info/PKG-INFO\n",
      "writing dependency_links to monarch_cuda.egg-info/dependency_links.txt\n",
      "writing top-level names to monarch_cuda.egg-info/top_level.txt\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:502: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "reading manifest file 'monarch_cuda.egg-info/SOURCES.txt'\n",
      "writing manifest file 'monarch_cuda.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_ext\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
      "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-cpython-310/monarch_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating stub loader for monarch_cuda.cpython-310-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/monarch_cuda.py to monarch_cuda.cpython-310.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying monarch_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying monarch_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying monarch_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying monarch_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.monarch_cuda.cpython-310: module references __file__\n",
      "creating 'dist/monarch_cuda-0.0.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing monarch_cuda-0.0.0-py3.10-linux-x86_64.egg\n",
      "removing '/usr/local/lib/python3.10/dist-packages/monarch_cuda-0.0.0-py3.10-linux-x86_64.egg' (and everything under it)\n",
      "creating /usr/local/lib/python3.10/dist-packages/monarch_cuda-0.0.0-py3.10-linux-x86_64.egg\n",
      "Extracting monarch_cuda-0.0.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
      "Adding monarch-cuda 0.0.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.10/dist-packages/monarch_cuda-0.0.0-py3.10-linux-x86_64.egg\n",
      "Processing dependencies for monarch-cuda==0.0.0\n",
      "Finished processing dependencies for monarch-cuda==0.0.0\n",
      "/workspace/l2/lyra/examples/flash-fft-conv\n",
      "running install\n",
      "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing flashfftconv.egg-info/PKG-INFO\n",
      "writing dependency_links to flashfftconv.egg-info/dependency_links.txt\n",
      "writing top-level names to flashfftconv.egg-info/top_level.txt\n",
      "reading manifest file 'flashfftconv.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "adding license file 'AUTHORS'\n",
      "writing manifest file 'flashfftconv.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/flashfftconv\n",
      "copying build/lib/flashfftconv/__init__.py -> build/bdist.linux-x86_64/egg/flashfftconv\n",
      "copying build/lib/flashfftconv/conv.py -> build/bdist.linux-x86_64/egg/flashfftconv\n",
      "copying build/lib/flashfftconv/depthwise_1d.py -> build/bdist.linux-x86_64/egg/flashfftconv\n",
      "copying build/lib/flashfftconv/sparse_conv.py -> build/bdist.linux-x86_64/egg/flashfftconv\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flashfftconv/__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flashfftconv/conv.py to conv.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flashfftconv/depthwise_1d.py to depthwise_1d.cpython-310.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/flashfftconv/sparse_conv.py to sparse_conv.cpython-310.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flashfftconv.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flashfftconv.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flashfftconv.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying flashfftconv.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/flashfftconv-0.0.0-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing flashfftconv-0.0.0-py3.10.egg\n",
      "Removing /usr/local/lib/python3.10/dist-packages/flashfftconv-0.0.0-py3.10.egg\n",
      "Copying flashfftconv-0.0.0-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
      "Adding flashfftconv 0.0.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.10/dist-packages/flashfftconv-0.0.0-py3.10.egg\n",
      "Processing dependencies for flashfftconv==0.0.0\n",
      "Finished processing dependencies for flashfftconv==0.0.0\n",
      "/workspace/l2/lyra/examples\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/HazyResearch/flash-fft-conv.git\n",
    "%cd flash-fft-conv\n",
    "%cd csrc/flashfftconv\n",
    "!python setup.py install\n",
    "%cd ../..\n",
    "!python setup.py install\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed368d-35a7-4143-937f-16f5ee3bdd2b",
   "metadata": {},
   "source": [
    "Sanity Check for FlashFFTConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4470294-80d9-4aef-9676-3f3cbfc6f793",
   "metadata": {},
   "source": [
    "## Restart the kernel to ensure succesfful FlashFFTConv installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c038ff-d3e3-410c-8183-453d0c1cfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pytest -s -q tests/test_conv1d.py\n",
    "# !pytest -s -q tests/test_flashfftconv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d6afd-702d-40a9-8a28-26f1df1fe351",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58c36ec-48dc-4901-bea6-6a6d53e751c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from flashfftconv import FlashDepthWiseConv1d\n",
    "from einops import rearrange, repeat\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "# Calculate the path to the directory containing 'lyra_base'\n",
    "current_dir = os.path.abspath('')\n",
    "parent_dir = os.path.join(current_dir, '..', '..')\n",
    "parent_dir_normalized = os.path.normpath(parent_dir)\n",
    "sys.path.append(parent_dir_normalized)\n",
    "\n",
    "from lyra import utils\n",
    "from lyra.utils import data_encoders\n",
    "from lyra.utils.data_encoders import one_hot_encode_protein, ProteinDataset\n",
    "from lyra.nn import lyra_base\n",
    "from lyra.nn.lyra_base import Lyra, lyra_example_proteins_config\n",
    "\n",
    "\n",
    "\n",
    "dropout_fn = nn.Dropout1d\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e508e97-846a-4263-a145-28a1cf670964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    sequences = df.iloc[:, 0].values  # Extract the first column\n",
    "    labels = df.iloc[:, 1].values   # Extract the second column\n",
    "    encoded_sequences = one_hot_encode_protein(sequences)\n",
    "    return encoded_sequences, torch.tensor(labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77778efb-2b6f-44f1-8752-1acaafc7b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "def load_data(file_path, has_header=False):\n",
    "    if has_header:\n",
    "        df = pd.read_csv(file_path)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, header=None, names=['sequence', 'label'])\n",
    "    return df\n",
    "\n",
    "def create_dataloaders(train_file, test_file, has_header=False, batch_size=512):\n",
    "    train_df = load_data(train_file, has_header)\n",
    "    test_df = load_data(test_file, has_header)\n",
    "\n",
    "    # Preprocess and one-hot encode the data\n",
    "    train_encoded, train_labels = preprocess_data(train_df)\n",
    "    test_encoded, test_labels = preprocess_data(test_df)\n",
    "\n",
    "    # Create train and test datasets with preprocessed data\n",
    "    train_dataset = ProteinDataset(train_encoded, train_labels)\n",
    "    test_dataset = ProteinDataset(test_encoded, test_labels)\n",
    "\n",
    "    # Create Data Loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=8)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# File paths\n",
    "datasets = {\n",
    "    \"GFP\": (\"../datasets/relso_data/GFP_train_data.csv\", \"../datasets/relso_data/GFP_test_data.csv\"),\n",
    "    \"GB1_WU\": (\"../datasets/relso_data/GB1_WU_train_data.csv\", \"../datasets/relso_data/GB1_WU_test_data.csv\"),\n",
    "    \"Gifford\": (\"../datasets/relso_data/gifford_train_data.csv\", \"../datasets/relso_data/gifford_test_data.csv\")\n",
    "}\n",
    "\n",
    "# Create a dictionary of data loaders\n",
    "dataloaders = {}\n",
    "for task, (train_file, test_file) in datasets.items():\n",
    "    dataloaders[task] = create_dataloaders(train_file, test_file, has_header=(task == \"Gifford\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48987fb-629e-491d-a2b8-3f2fb42055af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([512, 237, 20])\n",
      "Labels batch shape: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels = next(iter(dataloaders['GFP'][0]))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f9ba1f-0535-443b-9348-7d2984810386",
   "metadata": {},
   "source": [
    "# Model Instantiation\n",
    "\n",
    "This model instantiation is provided as a sanity check, the training loop in the next section will instantiate a new model for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ecc528-179b-4fb5-b343-8ab9e9819a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lyra(**lyra_example_proteins_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebe3d560-7e4d-424a-b67d-fa895c7423b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyra(\n",
      "  (encoder): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (pgc1): PGC(\n",
      "    (in_proj): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (in_norm): RMSNorm()\n",
      "    (conv): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), groups=16)\n",
      "    (flash_conv): FlashDepthWiseConv1d()\n",
      "    (out_proj): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (out_norm): RMSNorm()\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (pgc2): PGC(\n",
      "    (in_proj): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (in_norm): RMSNorm()\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
      "    (flash_conv): FlashDepthWiseConv1d()\n",
      "    (out_proj): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (out_norm): RMSNorm()\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (s4d): S4D(\n",
      "    (kernel): S4DKernel()\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): DropoutNd()\n",
      "    (flashfftconv): FlashFFTConv()\n",
      "    (output_linear): Sequential(\n",
      "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): GLU(dim=-2)\n",
      "    )\n",
      "  )\n",
      "  (norm): RMSNorm()\n",
      "  (decoder): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "Total trainable parameters: 47745\n"
     ]
    }
   ],
   "source": [
    "# Print model architecture\n",
    "print(model)\n",
    "\n",
    "# Count total trainable parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72d72e-a6ee-4943-9cda-e8e53ebba8a8",
   "metadata": {},
   "source": [
    "# Training and Evaluation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30b8f7df-f307-432a-80a6-7a032cbd61d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'d_input': 20, 'd_output': 1, 'd_model': 64, 'dropout': 0.2}\n",
      "Training on GFP dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d8c5d27f3d496fb3e10f65320637a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: Train Corr: 0.0000, Val Corr: 0.0000, Loss: 0.0000:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFP Maximum Spearman Correlation: 0.8592\n",
      "\n",
      "{'d_input': 20, 'd_output': 1, 'd_model': 64, 'dropout': 0.2}\n",
      "Training on GB1_WU dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd3420033b541659e06a336bdc282ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: Train Corr: 0.0000, Val Corr: 0.0000, Loss: 0.0000:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB1_WU Maximum Spearman Correlation: 0.6030\n",
      "\n",
      "{'d_input': 20, 'd_output': 1, 'd_model': 64, 'dropout': 0.2}\n",
      "Training on Gifford dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eb7efdc1a6498b902399cbeb5276c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: Train Corr: 0.0000, Val Corr: 0.0000, Loss: 0.0000:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gifford Maximum Spearman Correlation: 0.4823\n"
     ]
    }
   ],
   "source": [
    "rand_ID =  ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(8))\n",
    "\n",
    "for model_config in [lyra_example_proteins_config]:\n",
    "    for task, (train_loader, test_loader) in dataloaders.items():\n",
    "        print()\n",
    "        print(model_config)\n",
    "        print(f\"Training on {task} dataset\")\n",
    "        num_epochs = 500\n",
    "        max_spearman_corr = 0.00\n",
    "        model = Lyra(**model_config).to(device)\n",
    "        criterion = nn.MSELoss().to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001,weight_decay=0.01)\n",
    "        pbar = tqdm(range(num_epochs), desc=f\"Epoch 0: Train Corr: 0.0000, Val Corr: 0.0000, Loss: 0.0000\")\n",
    "\n",
    "        for epoch in pbar:\n",
    "            # Lists for storing batch-wise Spearman correlation\n",
    "            batch_train_spearman_corr = []\n",
    "            batch_val_spearman_corr = []\n",
    "        \n",
    "            # Training phase\n",
    "            model.train()\n",
    "            for sequences, labels in train_loader:\n",
    "                sequences = sequences.to(device)\n",
    "                labels = labels.to(device).unsqueeze(1)\n",
    "        \n",
    "                # Forward pass\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "        \n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                # Calculate batch-wise Spearman correlation\n",
    "                if outputs.is_cuda:\n",
    "                    outputs = outputs.cpu()\n",
    "                    labels = labels.cpu()\n",
    "                batch_corr = spearmanr(outputs.detach().numpy(), labels.detach().numpy()).statistic\n",
    "                batch_train_spearman_corr.append(batch_corr)\n",
    "        \n",
    "            # Average Spearman correlation over all batches\n",
    "            avg_train_spearman_corr = np.mean(batch_train_spearman_corr)\n",
    "        \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for sequences, labels in test_loader:\n",
    "                    sequences = sequences.to(device)\n",
    "                    labels = labels.to(device).unsqueeze(1)\n",
    "        \n",
    "                    outputs = model(sequences)\n",
    "        \n",
    "                    # Calculate batch-wise Spearman correlation\n",
    "                    if outputs.is_cuda:\n",
    "                        outputs = outputs.cpu()\n",
    "                        labels = labels.cpu()\n",
    "                    batch_corr = spearmanr(outputs.numpy(), labels.numpy()).statistic\n",
    "                    batch_val_spearman_corr.append(batch_corr)\n",
    "        \n",
    "            # Average Spearman correlation over all validation batches\n",
    "            avg_val_spearman_corr = np.mean(batch_val_spearman_corr)\n",
    "        \n",
    "            # Update maximum Spearman correlation\n",
    "            if avg_val_spearman_corr >= max_spearman_corr:\n",
    "                max_spearman_corr = avg_val_spearman_corr\n",
    "                # Save the model if desired\n",
    "        \n",
    "            pbar.set_description(f\"Epoch {epoch}: Train Corr: {avg_train_spearman_corr:.4f}, Val Corr: {avg_val_spearman_corr:.4f}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        \n",
    "        print(f'{task} Maximum Spearman Correlation: {max_spearman_corr:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb3ec2-d47e-44de-bf6c-149cffe8a8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
