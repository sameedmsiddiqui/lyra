{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qLI9xMdi_DQy",
   "metadata": {
    "id": "qLI9xMdi_DQy"
   },
   "source": [
    "# Lyra Colab instructions\n",
    "\n",
    "<details>\n",
    "  <summary>General Usage</summary>\n",
    "\n",
    "\n",
    "**We note to the user that Lyra runs significantly faster on a CUDA-enabled GPU version of colab, which can be accessed in \"Runtime\" → \"Change Runtime Type\" → \"T4 GPU\"**\n",
    "\n",
    "\n",
    "\n",
    "## General usage\n",
    "\n",
    "### 1. Data Format\n",
    "Your input CSV files should contain at minimum:\n",
    "1. A 'seq' column with the sequences\n",
    "2. A target column with your prediction values\n",
    "\n",
    "### 2. Configure your model and task\n",
    "Use the form to select:\n",
    "1. Sequence Type (RNA/DNA/Protein)\n",
    "2. Task Type (Regression/Classification)\n",
    "3. Data Files (train.csv, val.csv, test.csv)\n",
    "4. Label Column Name\n",
    "\n",
    "We note that by default this Colab notebook uses a train-val-test split, wherein\n",
    "the validation dataset is used after every epoch, and the best-performing model\n",
    "on the validation set will be saved and used on the test split.\n",
    "\n",
    "### 3. Press \"Play\" to train Lyra!\n",
    "\n",
    "### 4. (Optional) Use the saved Lyra model to make predictions on new data\n",
    "Ultimately, we want to use the trained Lyra model to make predictions on new data. The previous step saves the best trained Lyra model to \"best_model.pt\"; this next cell takes in an input file with a column 'seq' and automatically uses the best model to make predictions on this new data. All you have to do is enter the input file name and press \"Play\".\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>Advanced usage</summary>\n",
    "\n",
    "\n",
    "## Advanced usage\n",
    "### 1. For protein sequences with non-natural amino acids\n",
    "The default code operates on the 20 natural amino acids. To use a longer code,\n",
    "you must modify the encoding:\n",
    "1. Update the mapping array in one_hot_encode_protein()\n",
    "2. Add new rows to the mapping array for each additional amino acid\n",
    "3. Update char_to_int dictionary with new characters\n",
    "4. Update d_input in the Lyra model initialization accordingly\n",
    "\n",
    "### 2. Hyperparameter tuning\n",
    "The default version of Lyra works well in most use cases. Two two most common\n",
    "hyperparameters we find ourselves tuning are (1) epochs (2) dropout. The default\n",
    "model setup is for 50 epochs, which is sufficient for most tasks, and a dropout\n",
    "rate of 0.2. While internal model dimensions can be changed, and different PGC\n",
    "and S4D dimensions and counts can be used, in most cases we do not see significant improvement as compared to our default Lyra settings.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91948533-de33-4769-8118-09c29f2420bf",
   "metadata": {
    "cellView": "form",
    "id": "91948533-de33-4769-8118-09c29f2420bf"
   },
   "outputs": [],
   "source": [
    "#@title Load example data (optional)\n",
    "import gdown\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Data for APA Isoform prediction task from Bogard’s dataset\n",
    "# https://pubmed.ncbi.nlm.nih.gov/31178116/\n",
    "# Data collected and organized in the BEACON dataset paper:\n",
    "# https://arxiv.org/abs/2406.10391\n",
    "\n",
    "folder_url = \"https://drive.google.com/drive/folders/1NcEJZ_9C22R-XZT1ZMkTtYOiI0ik0jOj\"\n",
    "gdown.download_folder(folder_url, quiet=True, use_cookies=False)\n",
    "\n",
    "# Move downloaded files one level up\n",
    "for file_name in ['test.csv', 'train.csv', 'val.csv']:\n",
    "    shutil.move(os.path.join('Isoform/', file_name), os.path.join('', file_name))\n",
    "\n",
    "\n",
    "if False: # enable this if you want to test classification data\n",
    "  # Load the train, validation, and test files\n",
    "  train_df = pd.read_csv('train.csv')\n",
    "  val_df = pd.read_csv('val.csv')\n",
    "  test_df = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "  # Calculate the 33% and 66% percentiles from the training data\n",
    "  percentile_33 = train_df['proximal_isoform_proportion'].quantile(0.33)\n",
    "  percentile_66 = train_df['proximal_isoform_proportion'].quantile(0.66)\n",
    "\n",
    "\n",
    "  # Function to add classification column based on the percentiles\n",
    "  def add_classification(df, p33, p66):\n",
    "      conditions = [\n",
    "          (df['proximal_isoform_proportion'] < p33),\n",
    "          (df['proximal_isoform_proportion'] >= p33) & (df['proximal_isoform_proportion'] < p66),\n",
    "          (df['proximal_isoform_proportion'] >= p66)\n",
    "      ]\n",
    "      values = [0, 1, 2]\n",
    "      df['class'] = np.select(conditions, values)\n",
    "      return df\n",
    "\n",
    "  # Add classification column to all datasets using the same cutoffs\n",
    "  train_df = add_classification(train_df, percentile_33, percentile_66)\n",
    "  val_df = add_classification(val_df, percentile_33, percentile_66)\n",
    "  test_df = add_classification(test_df, percentile_33, percentile_66)\n",
    "\n",
    "  # Save the modified datasets\n",
    "  train_df.to_csv('train_classified.csv', index=False)\n",
    "  val_df.to_csv('val_classified.csv', index=False)\n",
    "  test_df.to_csv('test_classified.csv', index=False)\n",
    "  # print(\"\\nSaved classified datasets as train_classified.csv, val_classified.csv, and test_classified.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "kIn7QETPNIwZ",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "321e074458124a709b75018731cefc09",
      "c922fcc587114447a895b3ca3e52c38d",
      "3943a6b618e44446a69e2bec839810f9",
      "b10ecc2d068e4913ac79e57f9bfcf31f",
      "b870ea7feadc4250b364434971462447",
      "8dd20fa905964e289b0801a6456d1d09",
      "8b9920c695004aae8fc03d4e493690aa",
      "5859f44352724c998a8a8bc1d2506c11",
      "22a56abe26aa4605a2b9f0be9fa8354a",
      "2dd4298ecc5241c082931b7226c414f1",
      "4124d4888ef14e62976e79bcec2bdf33",
      "e1efdef9aacc453dab82e2a008a3814e",
      "b959111367674f8ca7e91e9019893ba5",
      "dc23fafe86084d4baacde13f0f43df4f",
      "960e5b9fc6094619be1f894293083719",
      "39de001a0d4d4fe287b11913890e354b",
      "68a81239a5324a2989ceed671cdf7ce6",
      "3c4e15f2539a45a886d95039e3bf1eb6",
      "9122a6de18c24d588e912331f9de74ac",
      "36ee6e0c98ae4f3896d2196aaf3043c3",
      "7ed0d072c3bf4ae7a34333751c23322e",
      "9bc72e101e1f4203a732d7844a83634d",
      "5f4f0f881af742548453d167a0e9135f",
      "70f015f1e9f84a16a9a6ba69a1e6d099",
      "c5eb03f30eea4c4ca92bf77a8544d661",
      "380b6f8caab442a298c752324a204d0c"
     ]
    },
    "id": "kIn7QETPNIwZ",
    "outputId": "0424b6a9-df0e-44b8-cd1d-42fc331604eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a78ba063d14a059641010fe12d5f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Sequence Type:', options=('RNA', 'DNA', 'Protein'), style=DescriptionStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Configure Run (press play to the left, then fill form and press \"Initialize task\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange, repeat\n",
    "from scipy.stats import spearmanr\n",
    "torch.manual_seed(42)\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "initialized = False\n",
    "\n",
    "class PGC(nn.Module):\n",
    "    def __init__(self,d_model,expansion_factor = 1.0,dropout = 0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.expansion_factor = expansion_factor\n",
    "        self.dropout = dropout\n",
    "        expanded_dim = int(d_model * expansion_factor)\n",
    "\n",
    "        self.conv = nn.Conv1d(expanded_dim,\n",
    "                              expanded_dim,\n",
    "                              kernel_size=3,\n",
    "                              padding=1,\n",
    "                              groups=expanded_dim)\n",
    "\n",
    "        self.in_proj = nn.Linear(d_model, int(d_model * expansion_factor * 2))\n",
    "        self.out_norm = nn.RMSNorm(int(d_model), eps=1e-8)\n",
    "        self.in_norm = nn.RMSNorm(expanded_dim * 2, eps=1e-8)\n",
    "        self.out_proj = nn.Linear(expanded_dim, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, u):\n",
    "        # Input projection and normalization\n",
    "        xv = self.in_norm(self.in_proj(u))\n",
    "\n",
    "        # Split projected input into two parts: x and v\n",
    "        x, v = xv.chunk(2, dim=-1)\n",
    "\n",
    "        # Depthwise convolution on x\n",
    "        x_conv = self.conv(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        # Gating mechanism\n",
    "        gate = v * x_conv\n",
    "\n",
    "        # Output projection and normalization\n",
    "        x_out = self.out_norm(self.out_proj(gate))\n",
    "\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class Lyra(nn.Module):\n",
    "    def __init__(self, d_input, d_output,d_model, d_state=64, dropout=0.2, transposed=False, **kernel_args):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "        self.pgc1 = PGC(d_model, expansion_factor=0.25, dropout=dropout)\n",
    "        self.pgc2 = PGC(d_model, expansion_factor=2, dropout=dropout)\n",
    "        self.s4d = S4D(d_model, d_state=d_state, dropout=dropout, transposed=transposed, **kernel_args)\n",
    "        self.norm = nn.RMSNorm(d_model)\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, u):\n",
    "        x = self.encoder(u)\n",
    "        x = self.pgc1(x)\n",
    "        x = self.pgc2(x)\n",
    "        z = x\n",
    "        z = self.norm(z)\n",
    "        x = self.dropout(self.s4d(z)) + x\n",
    "        x = x.mean(dim=1)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class DropoutNd(nn.Module):\n",
    "    def __init__(self, p: float = 0.5, tie=True, transposed=True):\n",
    "        \"\"\"\n",
    "        tie: tie dropout mask across sequence lengths (Dropout1d/2d/3d)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if p < 0 or p >= 1:\n",
    "            raise ValueError(\"dropout probability has to be in [0, 1), \" \"but got {}\".format(p))\n",
    "        self.p = p\n",
    "        self.tie = tie\n",
    "        self.transposed = transposed\n",
    "        self.binomial = torch.distributions.binomial.Binomial(probs=1-self.p)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"X: (batch, dim, lengths...).\"\"\"\n",
    "        if self.training:\n",
    "            if not self.transposed: X = rearrange(X, 'b ... d -> b d ...')\n",
    "            # binomial = torch.distributions.binomial.Binomial(probs=1-self.p) # This is incredibly slow because of CPU -> GPU copying\n",
    "            mask_shape = X.shape[:2] + (1,)*(X.ndim-2) if self.tie else X.shape\n",
    "            # mask = self.binomial.sample(mask_shape)\n",
    "            mask = torch.rand(*mask_shape, device=X.device) < 1.-self.p\n",
    "            X = X * mask * (1.0/(1-self.p))\n",
    "            if not self.transposed: X = rearrange(X, 'b d ... -> b ... d')\n",
    "            return X\n",
    "        return X\n",
    "\n",
    "class S4DKernel(nn.Module):\n",
    "    \"\"\"Generate convolution kernel from diagonal SSM parameters.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, N=64, dt_min=0.001, dt_max=0.1, lr=None):\n",
    "        super().__init__()\n",
    "        # Generate dt\n",
    "        H = d_model\n",
    "        log_dt = torch.rand(H) * (\n",
    "            math.log(dt_max) - math.log(dt_min)\n",
    "        ) + math.log(dt_min)\n",
    "\n",
    "        C = torch.randn(H, N // 2, dtype=torch.cfloat)\n",
    "        self.C = nn.Parameter(torch.view_as_real(C))\n",
    "        self.register(\"log_dt\", log_dt, lr)\n",
    "\n",
    "        log_A_real = torch.log(0.5 * torch.ones(H, N//2))\n",
    "        A_imag = math.pi * repeat(torch.arange(N//2), 'n -> h n', h=H)\n",
    "        self.register(\"log_A_real\", log_A_real, lr)\n",
    "        self.register(\"A_imag\", A_imag, lr)\n",
    "\n",
    "    def forward(self, L):\n",
    "        \"\"\"\n",
    "        returns: (..., c, L) where c is number of channels (default 1)\n",
    "        \"\"\"\n",
    "\n",
    "        # Materialize parameters\n",
    "        dt = torch.exp(self.log_dt) # (H)\n",
    "        C = torch.view_as_complex(self.C) # (H N)\n",
    "        A = -torch.exp(self.log_A_real) + 1j * self.A_imag # (H N)\n",
    "\n",
    "        # Vandermonde multiplication\n",
    "        dtA = A * dt.unsqueeze(-1)  # (H N)\n",
    "        K = dtA.unsqueeze(-1) * torch.arange(L, device=A.device) # (H N L)\n",
    "        C = C * (torch.exp(dtA)-1.) / A\n",
    "        K = 2 * torch.einsum('hn, hnl -> hl', C, torch.exp(K)).real\n",
    "\n",
    "        return K\n",
    "\n",
    "    def register(self, name, tensor, lr=None):\n",
    "        \"\"\"Register a tensor with a configurable learning rate and 0 weight decay\"\"\"\n",
    "\n",
    "        if lr == 0.0:\n",
    "            self.register_buffer(name, tensor)\n",
    "        else:\n",
    "            self.register_parameter(name, nn.Parameter(tensor))\n",
    "\n",
    "            optim = {\"weight_decay\": 0.0}\n",
    "            if lr is not None: optim[\"lr\"] = lr\n",
    "            setattr(getattr(self, name), \"_optim\", optim)\n",
    "\n",
    "\n",
    "class S4D(nn.Module):\n",
    "    def __init__(self, d_model, d_state=64, dropout=0.0, transposed=True, **kernel_args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.h = d_model\n",
    "        self.n = d_state\n",
    "        self.d_output = self.h\n",
    "        self.transposed = transposed\n",
    "\n",
    "        self.D = nn.Parameter(torch.randn(self.h))\n",
    "        # SSM Kernel\n",
    "        self.kernel = S4DKernel(self.h, N=self.n, **kernel_args)\n",
    "        # Pointwise\n",
    "        self.activation = nn.GELU()\n",
    "        dropout_fn = DropoutNd\n",
    "        self.dropout = dropout_fn(dropout) if dropout > 0.0 else nn.Identity()\n",
    "\n",
    "        # position-wise output transform to mix features\n",
    "        self.output_linear = nn.Sequential(\n",
    "            nn.Conv1d(self.h, 2*self.h, kernel_size=1),\n",
    "            nn.GLU(dim=-2),\n",
    "        )\n",
    "\n",
    "    def forward(self, u, **kwargs): # absorbs return_output and transformer src mask\n",
    "        \"\"\" Input and output shape (B, H, L) \"\"\"\n",
    "        if not self.transposed: u = u.transpose(-1, -2)\n",
    "        L = u.size(-1)\n",
    "        # Compute SSM Kernel\n",
    "        k = self.kernel(L=L) # (H L)\n",
    "\n",
    "        # Convolution\n",
    "        k_f = torch.fft.rfft(k, n=2*L)  # (H L)\n",
    "        u_f = torch.fft.rfft(u, n=2*L) # (B H L)\n",
    "        y = torch.fft.irfft(u_f*k_f, n=2*L)[..., :L] # (B H L)\n",
    "\n",
    "        # Compute D term in state space equation - essentially a skip connection\n",
    "        y = y + u * self.D.unsqueeze(-1)\n",
    "\n",
    "        y = self.dropout(self.activation(y))\n",
    "        y = self.output_linear(y)\n",
    "        if not self.transposed: y = y.transpose(-1, -2)\n",
    "        return y\n",
    "\n",
    "def one_hot_encode_sequences_RNA(sequences):\n",
    "    \"\"\"\n",
    "    Vectorized one-hot encoding of sequences with padding.\n",
    "\n",
    "    Args:\n",
    "    - sequences (list of str): List of sequences (e.g., sgrna or target).\n",
    "\n",
    "    Returns:\n",
    "    - Tensor: The one-hot encoded sequences as a batch.\n",
    "    \"\"\"\n",
    "    # Define the one-hot encoding for RNA/DNA bases\n",
    "    mapping = np.array([\n",
    "        [1, 0, 0, 0],  # A\n",
    "        [0, 1, 0, 0],  # T\n",
    "        [0, 0, 1, 0],  # C\n",
    "        [0, 0, 0, 1],  # G\n",
    "        [0.0, 0.0, 0.0, 0.0],  # N (unknown base or padding)\n",
    "        [0.0, 0.0, 0.0, 0.0]  # X (unknown base or padding)\n",
    "\n",
    "    ])\n",
    "    char_to_int = {c: i for i, c in enumerate('ATCGNX')}  # Map each base to an index\n",
    "\n",
    "    # Find the maximum sequence length\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "\n",
    "    # Pad sequences with 'N' to the max length\n",
    "    padded_sequences = [seq.ljust(max_length, 'N') for seq in sequences]\n",
    "\n",
    "    # Vectorized conversion of sequences to indices\n",
    "    seq_indices = [[char_to_int[char] for char in seq] for seq in padded_sequences]\n",
    "    encoded = np.array([mapping[seq] for seq in seq_indices])\n",
    "\n",
    "    return torch.tensor(encoded, dtype=torch.float32)\n",
    "\n",
    "# One hot encoding for DNA Datasets\n",
    "\n",
    "def one_hot_encode_dna(sequences):\n",
    "    \"\"\"\n",
    "    Vectorized one-hot encoding of DNA sequences.\n",
    "\n",
    "    Args:\n",
    "    - sequences (list of str): List of DNA sequences.\n",
    "\n",
    "    Returns:\n",
    "    - Tensor: The one-hot encoded DNA sequences as a batch.\n",
    "    \"\"\"\n",
    "    # Define the mapping in a vectorized form\n",
    "    mapping = np.array([\n",
    "        [1, 0, 0, 0],  # A\n",
    "        [0, 1, 0, 0],  # C\n",
    "        [0, 0, 1, 0],  # G\n",
    "        [0, 0, 0, 1],  # T\n",
    "        [0.25, 0.25, 0.25, 0.25],  # N (unknown base)\n",
    "    ])\n",
    "    char_to_int = {c: i for i, c in enumerate('ACGTN')}\n",
    "\n",
    "    # Vectorized conversion of sequences to indices\n",
    "    seq_indices = [[char_to_int.get(char.upper(), 4) for char in seq] for seq in sequences]\n",
    "    encoded = np.array([mapping[seq] for seq in seq_indices])\n",
    "\n",
    "    return torch.tensor(encoded, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# One hot encoding for Protein Datasets\n",
    "\n",
    "def one_hot_encode_protein(sequences):\n",
    "    \"\"\"\n",
    "    Vectorized one-hot encoding of protein sequences.\n",
    "\n",
    "    Args:\n",
    "    - sequences (list of str): List of protein sequences.\n",
    "\n",
    "    Returns:\n",
    "    - Tensor: The one-hot encoded DNA sequences as a batch.\n",
    "    \"\"\"\n",
    "    # Define the mapping in a vectorized form\n",
    "    # NB: depending on the dataset (i.e. if there are non-natural amino acids\n",
    "    # you may have to change the one-hot encoding mapping)\n",
    "    mapping = np.array([\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # I\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # L\n",
    "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # V\n",
    "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # F\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # M\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # C\n",
    "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # A\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # G\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # P\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # T\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # S\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # Y\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # W\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],  # Q\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # N\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],  # H\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],  # E\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # D\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],  # K\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],  # R\n",
    "        [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],  # X\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   # J\n",
    "    ])\n",
    "    char_to_int = {c: i for i, c in enumerate('ILVFMCAGPTSYWQNHEDKRXJ')}\n",
    "\n",
    "    # Vectorized conversion of sequences to indices\n",
    "    seq_indices = [[char_to_int[char] for char in seq] for seq in sequences]\n",
    "    encoded = np.array([mapping[seq] for seq in seq_indices])\n",
    "\n",
    "    return torch.tensor(encoded, dtype=torch.float32)\n",
    "\n",
    "class RNADataset(Dataset):\n",
    "    def __init__(self, encoded_sequences, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with preprocessed RNA data.\n",
    "\n",
    "        Args:\n",
    "        - encoded_sequences (Tensor): Encoded RNA sequences.\n",
    "        - labels (Tensor): Corresponding labels.\n",
    "        \"\"\"\n",
    "        self.encoded_sequences = encoded_sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_sequences[index], torch.tensor(self.labels[index], dtype=torch.float32)\n",
    "\n",
    "\n",
    "# One hot encoding for DNA Datasets\n",
    "class DNADataset(Dataset):\n",
    "    def __init__(self, encoded_sequences, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with preprocessed data.\n",
    "\n",
    "        Args:\n",
    "        - encoded_sequences (Tensor): Encoded sequences.\n",
    "        - labels (Tensor): Corresponding labels.\n",
    "        \"\"\"\n",
    "        self.encoded_sequences = encoded_sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_sequences[index], torch.tensor(self.labels[index], dtype=torch.float32)\n",
    "\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, encoded_sequences, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with preprocessed data.\n",
    "\n",
    "        Args:\n",
    "        - encoded_sequences (Tensor): Encoded sequences.\n",
    "        - labels (Tensor): Corresponding labels.\n",
    "        \"\"\"\n",
    "        self.encoded_sequences = encoded_sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_sequences[index], torch.tensor(self.labels[index], dtype=torch.float32)\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def setup_sequence_model(sequence_type):\n",
    "    \"\"\"\n",
    "    Configure the appropriate dataset class and encoder based on sequence type.\n",
    "\n",
    "    Args:\n",
    "    - sequence_type (str): One of 'RNA', 'DNA', or 'Protein'\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (dataset_class, encoder_function, d_input)\n",
    "    \"\"\"\n",
    "    if sequence_type.upper() == 'RNA':\n",
    "        return RNADataset, one_hot_encode_sequences_RNA, 4\n",
    "    elif sequence_type.upper() == 'DNA':\n",
    "        return DNADataset, one_hot_encode_dna, 4\n",
    "    elif sequence_type.upper() == 'PROTEIN':\n",
    "        return ProteinDataset, one_hot_encode_protein, 20\n",
    "    else:\n",
    "        raise ValueError(\"sequence_type must be one of: 'RNA', 'DNA', 'Protein'\")\n",
    "\n",
    "def load_and_prepare_data(train_file, val_file, test_file, label_name, Dataset, encoder):\n",
    "    \"\"\"\n",
    "    Load and prepare data for training.\n",
    "\n",
    "    Args:\n",
    "    - train_file (str): Path to training data CSV\n",
    "    - val_file (str): Path to validation data CSV\n",
    "    - test_file (str): Path to test data CSV\n",
    "    - label_name (str): Name of the label column in CSVs\n",
    "    - Dataset (class): Dataset class to use\n",
    "    - encoder (function): Encoding function to use\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    try:\n",
    "        train_df = pd.read_csv(train_file)\n",
    "        val_df = pd.read_csv(val_file)\n",
    "        test_df = pd.read_csv(test_file)\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"Could not find one or more data files. Please check the file paths: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading data files: {str(e)}\")\n",
    "\n",
    "    # Verify label column exists\n",
    "    if label_name not in train_df.columns:\n",
    "        raise ValueError(f\"Label column '{label_name}' not found in data files. Available columns: {train_df.columns.tolist()}\")\n",
    "\n",
    "    # Encode sequences and prepare labels\n",
    "    train_seqs = encoder(train_df['seq'].values)\n",
    "    val_seqs = encoder(val_df['seq'].values)\n",
    "    test_seqs = encoder(test_df['seq'].values)\n",
    "\n",
    "    train_labels = train_df[label_name].values\n",
    "    val_labels = val_df[label_name].values\n",
    "    test_labels = test_df[label_name].values\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = Dataset(train_seqs, train_labels)\n",
    "    val_dataset = Dataset(val_seqs, val_labels)\n",
    "    test_dataset = Dataset(test_seqs, test_labels)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    print(f\"\\nData loaded successfully:\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def create_setup_form():\n",
    "    \"\"\"Creates and returns the setup form widgets\"\"\"\n",
    "    # Create widgets\n",
    "    sequence_type_dropdown = widgets.Dropdown(\n",
    "        options=['RNA', 'DNA', 'Protein'],\n",
    "        value='RNA',\n",
    "        description='Sequence Type:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    task_type_dropdown = widgets.Dropdown(\n",
    "        options=['Regression', 'Classification'],\n",
    "        value='Regression',\n",
    "        description='Task Type:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    num_classes_input = widgets.IntText(\n",
    "        value=2,\n",
    "        min=2,\n",
    "        description='Number of Classes:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout={'visibility': 'hidden'}  # Hidden by default for regression\n",
    "    )\n",
    "\n",
    "    train_file_input = widgets.Text(\n",
    "        value='train.csv',\n",
    "        description='Training Data File:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    val_file_input = widgets.Text(\n",
    "        value='val.csv',\n",
    "        description='Validation Data File:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    test_file_input = widgets.Text(\n",
    "        value='test.csv',\n",
    "        description='Testing Data File:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    label_name_input = widgets.Text(\n",
    "        value='proximal_isoform_proportion',\n",
    "        description='Label Column Name:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Function to handle task type changes\n",
    "    def on_task_change(change):\n",
    "        if change['new'] == 'Classification':\n",
    "            num_classes_input.layout.visibility = 'visible'\n",
    "        else:\n",
    "            num_classes_input.layout.visibility = 'hidden'\n",
    "\n",
    "    task_type_dropdown.observe(on_task_change, names='value')\n",
    "\n",
    "    # Button to confirm selections\n",
    "    confirm_button = widgets.Button(description=\"Initialize Task\")\n",
    "\n",
    "    def on_button_click(b):\n",
    "        clear_output()\n",
    "        # Re-display the form\n",
    "        display(widgets.VBox([\n",
    "            sequence_type_dropdown,\n",
    "            task_type_dropdown,\n",
    "            num_classes_input,\n",
    "            train_file_input,\n",
    "            val_file_input,\n",
    "            test_file_input,\n",
    "            label_name_input,\n",
    "            confirm_button\n",
    "        ]))\n",
    "\n",
    "        try:\n",
    "            # Get configuration\n",
    "            global sequence_type, task_type\n",
    "            sequence_type = sequence_type_dropdown.value\n",
    "            task_type = task_type_dropdown.value\n",
    "            train_file = train_file_input.value\n",
    "            val_file = val_file_input.value\n",
    "            test_file = test_file_input.value\n",
    "            label_name = label_name_input.value\n",
    "\n",
    "            # Set up model configuration\n",
    "            Dataset, encoder, d_input = setup_sequence_model(sequence_type)\n",
    "            global d_output\n",
    "            d_output = num_classes_input.value if task_type == 'Classification' else 1\n",
    "\n",
    "            # Print configuration\n",
    "            print(f\"\\nSelected Configuration:\")\n",
    "            print(f\"Sequence Type: {sequence_type} (d_input = {d_input})\")\n",
    "            print(f\"Task Type: {task_type} (d_output = {d_output})\")\n",
    "            print(f\"\\nData Files:\")\n",
    "            print(f\"Training: {train_file}\")\n",
    "            print(f\"Validation: {val_file}\")\n",
    "            print(f\"Testing: {test_file}\")\n",
    "            print(f\"Label Column: {label_name}\")\n",
    "\n",
    "            # Load and prepare data\n",
    "            global train_loader, val_loader, test_loader\n",
    "            print(f\"\\nLoading data, this may take a while - \" +\n",
    "              \"do not re-press \\\"Initialize Task\\\"\")\n",
    "\n",
    "            train_loader, val_loader, test_loader = load_and_prepare_data(\n",
    "                train_file, val_file, test_file, label_name, Dataset, encoder\n",
    "            )\n",
    "\n",
    "            # Calculate class weights for classification tasks\n",
    "            global class_weights\n",
    "            if task_type == 'Classification':\n",
    "                # Get all labels from the training set\n",
    "                all_labels = []\n",
    "                for _, labels in train_loader:\n",
    "                    all_labels.append(labels)\n",
    "                all_labels = torch.cat(all_labels)\n",
    "\n",
    "                # Count occurrences of each class\n",
    "                train_counts = torch.bincount(all_labels.long())\n",
    "                total_samples = len(all_labels)\n",
    "\n",
    "                # Calculate weights (inverse of frequency)\n",
    "                class_weights = torch.tensor([total_samples / count for count in train_counts], device=device)\n",
    "\n",
    "                print(f\"\\nClass distribution: {train_counts.tolist()}\")\n",
    "                print(f\"Class weights: {class_weights.tolist()}\")\n",
    "            else:\n",
    "                class_weights = None\n",
    "\n",
    "\n",
    "            # Initialize model\n",
    "            global model  # Make model accessible outside this function\n",
    "            model = Lyra(d_input=d_input, d_output=d_output, d_model=64).to(device)\n",
    "            print(\"\\nModel initialized successfully!\")\n",
    "            global initialized\n",
    "            initialized = True\n",
    "            # print(model)\n",
    "            # print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n",
    "            print(\"\\nPlease check your configuration and try again.\")\n",
    "\n",
    "    confirm_button.on_click(on_button_click)\n",
    "\n",
    "    # Return the form\n",
    "    return widgets.VBox([\n",
    "        sequence_type_dropdown,\n",
    "        task_type_dropdown,\n",
    "        num_classes_input,\n",
    "        train_file_input,\n",
    "        val_file_input,\n",
    "        test_file_input,\n",
    "        label_name_input,\n",
    "        confirm_button\n",
    "    ])\n",
    "\n",
    "form = create_setup_form()\n",
    "display(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6rYpOq-Io5FE",
   "metadata": {
    "cellView": "form",
    "id": "6rYpOq-Io5FE"
   },
   "outputs": [],
   "source": [
    "#@title Check if you're using a CUDA-enabled GPU (you can do this by selecting \"Runtime\" → \"Change Runtime Type\" → \"T4 GPU\")\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ CUDA is available! You're using a GPU-enabled setup.\")\n",
    "else:\n",
    "    print(\"❌ CUDA is NOT available. You're running on CPU - this will be much slower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326d590-394a-476f-ad7f-b9102ced0e7a",
   "metadata": {
    "cellView": "form",
    "id": "e326d590-394a-476f-ad7f-b9102ced0e7a"
   },
   "outputs": [],
   "source": [
    "#@title Train Lyra!\n",
    "print_results_from_every_epoch = False #@param {type:\"boolean\"}\n",
    "num_epochs = 50 #@param {type:\"integer\"}\n",
    "\n",
    "\n",
    "\n",
    "class ModelNotInitializedError(Exception): pass\n",
    "if not initialized: raise ModelNotInitializedError(\n",
    "    \"You never initialized the model in the previous cell\")\n",
    "\n",
    "# Initialize lists to store performance metrics for different data volumes\n",
    "lyra_metrics = []\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "\n",
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    # Calculate R^2 score and Spearman's rank correlation coefficient\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    spearman = spearmanr(y_true, y_pred).correlation\n",
    "    return r2, spearman\n",
    "\n",
    "def calculate_classification_metrics(y_true, y_pred, y_scores):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Check if binary or multiclass classification\n",
    "    num_classes = len(np.unique(y_true))\n",
    "\n",
    "    if num_classes == 2:\n",
    "        # Binary classification metrics\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        specificity = tn / (tn + fp)\n",
    "        auc_roc = roc_auc_score(y_true, y_scores)\n",
    "        true_positive_rate = tp / (tp + fn)\n",
    "        return accuracy, specificity, f1, auc_roc, recall, true_positive_rate\n",
    "    else:\n",
    "        # Multiclass classification metrics\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "        # For multiclass, calculate a macro-averaged specificity\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        specificities = []\n",
    "        true_positive_rates = []\n",
    "\n",
    "        # Calculate specificity for each class\n",
    "        for i in range(num_classes):\n",
    "            true_neg = np.sum(cm) - np.sum(cm[i, :]) - np.sum(cm[:, i]) + cm[i, i]\n",
    "            false_pos = np.sum(cm[:, i]) - cm[i, i]\n",
    "            false_neg = np.sum(cm[i, :]) - cm[i, i]\n",
    "            true_pos = cm[i, i]\n",
    "\n",
    "            # Avoid division by zero\n",
    "            if (true_neg + false_pos) > 0:\n",
    "                specificities.append(true_neg / (true_neg + false_pos))\n",
    "            else:\n",
    "                specificities.append(0)\n",
    "\n",
    "            if (true_pos + false_neg) > 0:\n",
    "                true_positive_rates.append(true_pos / (true_pos + false_neg))\n",
    "            else:\n",
    "                true_positive_rates.append(0)\n",
    "\n",
    "        # Macro-average the metrics\n",
    "        specificity = np.mean(specificities)\n",
    "        true_positive_rate = np.mean(true_positive_rates)\n",
    "\n",
    "        # For multiclass ROC AUC, use one-vs-rest approach if y_scores has probabilities for each class\n",
    "        if isinstance(y_scores, np.ndarray) and y_scores.ndim == 2 and y_scores.shape[1] == num_classes:\n",
    "            try:\n",
    "                auc_roc = roc_auc_score(y_true, y_scores, multi_class='ovr')\n",
    "            except:\n",
    "                auc_roc = 0  # Fallback if ROC AUC calculation fails\n",
    "        else:\n",
    "            auc_roc = 0  # Not applicable if scores aren't available for all classes\n",
    "\n",
    "        return accuracy, specificity, f1, auc_roc, recall, true_positive_rate\n",
    "\n",
    "# Set criterion based on task type\n",
    "if task_type == 'Classification':\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "else:\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "# Train models with different data volumes\n",
    "# Train lyra model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "best_lyra_loss = float('inf')\n",
    "best_lyra_r2 = float('-inf')  # Track the best R^2 score\n",
    "best_model_state = None\n",
    "\n",
    "tqdm_bar = tqdm(range(num_epochs), desc='Training Progress')\n",
    "\n",
    "for epoch in tqdm_bar:\n",
    "    model.train()\n",
    "    lyra_train_loss = 0\n",
    "    lyra_train_true = []\n",
    "    lyra_train_pred = []\n",
    "    lyra_train_scores = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        lyra_outputs = model(inputs)\n",
    "        if task_type == 'Classification':\n",
    "            labels = labels.long()\n",
    "            lyra_loss = criterion(lyra_outputs, labels)\n",
    "        else:\n",
    "            lyra_loss = criterion(lyra_outputs.squeeze(), labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        lyra_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lyra_train_loss += lyra_loss.item()\n",
    "        if task_type == 'Classification':\n",
    "            _, predicted = torch.max(lyra_outputs.data, 1)\n",
    "            lyra_train_true.extend(labels.cpu().numpy())\n",
    "            lyra_train_pred.extend(predicted.cpu().numpy())\n",
    "            # Store all class probabilities for multiclass\n",
    "            lyra_train_scores.extend(torch.softmax(lyra_outputs, dim=1).cpu().detach().numpy())\n",
    "        else:\n",
    "            lyra_train_true.append(labels.detach().cpu().numpy())\n",
    "            lyra_train_pred.append(lyra_outputs.squeeze().detach().cpu().numpy())\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    lyra_loss = 0\n",
    "    lyra_true = []\n",
    "    lyra_pred = []\n",
    "    lyra_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            lyra_outputs = model(inputs)\n",
    "            if task_type == 'Classification':\n",
    "                labels = labels.long()\n",
    "                lyra_loss = criterion(lyra_outputs, labels)\n",
    "            else:\n",
    "                lyra_loss = criterion(lyra_outputs.squeeze(), labels)\n",
    "\n",
    "            lyra_loss += lyra_loss.item()\n",
    "            if task_type == 'Classification':\n",
    "                _, predicted = torch.max(lyra_outputs.data, 1)\n",
    "                lyra_true.extend(labels.cpu().numpy())\n",
    "                lyra_pred.extend(predicted.cpu().numpy())\n",
    "                # Store all class probabilities for multiclass\n",
    "                lyra_scores.extend(torch.softmax(lyra_outputs, dim=1).cpu().detach().numpy())\n",
    "            else:\n",
    "                lyra_true.append(labels.detach().cpu().numpy())\n",
    "                lyra_pred.append(lyra_outputs.squeeze().detach().cpu().numpy())\n",
    "\n",
    "        if task_type == 'Classification':\n",
    "            lyra_true = np.array(lyra_true)\n",
    "            lyra_pred = np.array(lyra_pred)\n",
    "            lyra_scores = np.array(lyra_scores)\n",
    "        else:\n",
    "            lyra_true = np.concatenate(lyra_true)\n",
    "            lyra_pred = np.concatenate(lyra_pred)\n",
    "\n",
    "    # Calculate and print validation statistics for this epoch\n",
    "    if task_type == 'Classification':\n",
    "        epoch_accuracy, epoch_specificity, epoch_f1, epoch_auc_roc, epoch_recall, epoch_true_positive_rate = calculate_classification_metrics(lyra_true, lyra_pred, lyra_scores)\n",
    "        if print_results_from_every_epoch:\n",
    "            tqdm.write(f\"\\nEpoch {epoch+1} Validation Statistics:\")\n",
    "            tqdm.write(f\"Validation Loss: {lyra_loss/len(val_loader):.8f}\")\n",
    "            tqdm.write(f\"Accuracy: {epoch_accuracy:.4f}, Specificity: {epoch_specificity:.4f}, F1 Score: {epoch_f1:.4f}, AUC-ROC: {epoch_auc_roc:.4f}, Recall: {epoch_recall:.4f}, True Positive Rate: {epoch_true_positive_rate:.4f}\")\n",
    "    else:\n",
    "        epoch_r2, epoch_spearman = calculate_regression_metrics(lyra_true, lyra_pred)\n",
    "        if print_results_from_every_epoch:\n",
    "            tqdm.write(f\"\\nEpoch {epoch+1} Validation Statistics:\")\n",
    "            tqdm.write(f\"Validation Loss: {lyra_loss/len(val_loader):.8f}\")\n",
    "            tqdm.write(f\"R^2 Score: {epoch_r2:.4f}\")\n",
    "            tqdm.write(f\"Spearman's Rank Correlation: {epoch_spearman:.4f}\")\n",
    "\n",
    "    # Update tqdm description with current epoch metrics\n",
    "    if task_type == 'Classification':\n",
    "        tqdm_bar.set_description(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {lyra_train_loss/len(train_loader):.8f}, Val Loss: {lyra_loss/len(val_loader):.8f}, Val Accuracy: {epoch_accuracy:.4f}, Val F1: {epoch_f1:.4f}')\n",
    "    else:\n",
    "        tqdm_bar.set_description(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {lyra_train_loss/len(train_loader):.8f}, Val Loss: {lyra_loss/len(val_loader):.8f}, Val R^2: {epoch_r2:.4f}, Val Spearman: {epoch_spearman:.4f}')\n",
    "\n",
    "    # Save the best model based on Validation performance\n",
    "    if task_type == 'Classification':\n",
    "        # For multiclass, use accuracy as the metric to determine best model\n",
    "        # For binary, continue using TPR\n",
    "        num_classes = len(np.unique(lyra_true))\n",
    "        if num_classes == 2:\n",
    "            current_metric = epoch_true_positive_rate\n",
    "        else:\n",
    "            current_metric = epoch_accuracy\n",
    "\n",
    "        if current_metric > best_lyra_r2:\n",
    "            best_lyra_r2 = current_metric\n",
    "            best_model_state = model.state_dict()\n",
    "    else:\n",
    "        if epoch_r2 > best_lyra_r2:\n",
    "            best_lyra_r2 = epoch_r2\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    if lyra_loss < best_lyra_loss:\n",
    "        best_lyra_loss = lyra_loss\n",
    "\n",
    "# Load the best model and evaluate on test set\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "lyra_test_loss = 0\n",
    "lyra_test_true = []\n",
    "lyra_test_pred = []\n",
    "lyra_test_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc='Final Test Evaluation'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        lyra_outputs = model(inputs)\n",
    "        if task_type == 'Classification':\n",
    "            labels = labels.long()\n",
    "            lyra_loss = criterion(lyra_outputs, labels)\n",
    "        else:\n",
    "            lyra_loss = criterion(lyra_outputs.squeeze(), labels)\n",
    "\n",
    "        lyra_test_loss += lyra_loss.item()\n",
    "        if task_type == 'Classification':\n",
    "            _, predicted = torch.max(lyra_outputs.data, 1)\n",
    "            lyra_test_true.extend(labels.cpu().numpy())\n",
    "            lyra_test_pred.extend(predicted.cpu().numpy())\n",
    "            # Store all class probabilities for multiclass\n",
    "            lyra_test_scores.extend(torch.softmax(lyra_outputs, dim=1).cpu().detach().numpy())\n",
    "        else:\n",
    "            lyra_test_true.append(labels.detach().cpu().numpy())\n",
    "            lyra_test_pred.append(lyra_outputs.squeeze().detach().cpu().numpy())\n",
    "\n",
    "    if task_type == 'Classification':\n",
    "        lyra_test_true = np.array(lyra_test_true)\n",
    "        lyra_test_pred = np.array(lyra_test_pred)\n",
    "        lyra_test_scores = np.array(lyra_test_scores)\n",
    "    else:\n",
    "        lyra_test_true = np.concatenate(lyra_test_true)\n",
    "        lyra_test_pred = np.concatenate(lyra_test_pred)\n",
    "\n",
    "# Calculate final test metrics\n",
    "if task_type == 'Classification':\n",
    "    final_test_accuracy, final_test_specificity, final_test_f1, final_test_auc_roc, final_test_recall, final_test_true_positive_rate = calculate_classification_metrics(lyra_test_true, lyra_test_pred, lyra_test_scores)\n",
    "    final_test_loss = lyra_test_loss / len(test_loader)\n",
    "\n",
    "    # Check if binary or multiclass for final metrics\n",
    "    num_classes = len(np.unique(lyra_test_true))\n",
    "    if num_classes == 2:\n",
    "        # Binary classification metrics\n",
    "        lyra_metrics.append({\n",
    "            '_val_loss': best_lyra_loss,\n",
    "            'best_val_metric': best_lyra_r2,\n",
    "            'test_loss': final_test_loss,\n",
    "            'test_accuracy': final_test_accuracy,\n",
    "            'test_specificity': final_test_specificity,\n",
    "            'test_f1': final_test_f1,\n",
    "            'test_auc_roc': final_test_auc_roc,\n",
    "            'test_recall': final_test_recall,\n",
    "            'test_true_positive_rate': final_test_true_positive_rate\n",
    "        })\n",
    "    else:\n",
    "        # Multiclass classification metrics\n",
    "        # Include class-specific metrics\n",
    "        class_precision, class_recall, class_f1, class_support = precision_recall_fscore_support(\n",
    "            lyra_test_true, lyra_test_pred, average=None\n",
    "        )\n",
    "\n",
    "        # Create a dictionary with class-specific metrics\n",
    "        class_metrics = {}\n",
    "        for i in range(num_classes):\n",
    "            class_metrics[f'class_{i}_precision'] = class_precision[i]\n",
    "            class_metrics[f'class_{i}_recall'] = class_recall[i]\n",
    "            class_metrics[f'class_{i}_f1'] = class_f1[i]\n",
    "            class_metrics[f'class_{i}_support'] = class_support[i]\n",
    "\n",
    "        # Add confusion matrix\n",
    "        cm = confusion_matrix(lyra_test_true, lyra_test_pred)\n",
    "\n",
    "        # Combine all metrics\n",
    "        lyra_metrics.append({\n",
    "            '_val_loss': best_lyra_loss,\n",
    "            'best_val_metric': best_lyra_r2,\n",
    "            'test_loss': final_test_loss,\n",
    "            'test_accuracy': final_test_accuracy,\n",
    "            'test_macro_f1': final_test_f1,\n",
    "            'test_macro_recall': final_test_recall,\n",
    "            'test_macro_specificity': final_test_specificity,\n",
    "            'test_macro_true_positive_rate': final_test_true_positive_rate,\n",
    "            'test_auc_roc': final_test_auc_roc,\n",
    "            'confusion_matrix': cm.tolist(),\n",
    "            **class_metrics  # Include all class-specific metrics\n",
    "        })\n",
    "else:\n",
    "    final_test_r2, final_test_spearman = calculate_regression_metrics(lyra_test_true, lyra_test_pred)\n",
    "    final_test_loss = lyra_test_loss / len(test_loader)\n",
    "    lyra_metrics.append({\n",
    "        '_val_loss': best_lyra_loss,\n",
    "        'best_val_r2': best_lyra_r2,\n",
    "        'test_loss': final_test_loss,\n",
    "        'test_r2': final_test_r2,\n",
    "        'test_spearman': final_test_spearman\n",
    "    })\n",
    "\n",
    "# Save the best model\n",
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "global model_name\n",
    "model_name = f\"best_lyra_model_{task_type}_{sequence_type}_{current_time}.pt\"\n",
    "torch.save({'model_state_dict': model.state_dict(), 'sequence_type': sequence_type}, model_name)\n",
    "print(f\"Model saved as: {model_name}\")\n",
    "display(lyra_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56d9bfbc-cf82-4e3a-8f5a-1ee83e12b55b",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "176d482f231d4f20b408e66da9a7d588",
      "da4ad9e2a06e433dad0255452ad9d011",
      "930be6577c3e41ab9ed9547afa2dc07a",
      "bef25abf18e34bdebfab53e2eb4e48ed",
      "d18549085fd2499281a0b0500d47df95",
      "fdb8d963015a47b29b5049c97ec4d544",
      "4ee3454d820840eaa674f6bbef669e25",
      "34aeb16e679d438c962330b3dc7f0a79",
      "bdeb409071e34b3d9537c47cd6187c66",
      "94378188bd324da09e3692ca6b54a94e",
      "3604eec120694a5f842117483be553e1",
      "12f1342c560e4f69b0e1a3fd7a14d32c",
      "2cbc054083e34a0b83a05d6f679d1cce",
      "ec8cfc6604a849458cacbcd5725cd022"
     ]
    },
    "id": "56d9bfbc-cf82-4e3a-8f5a-1ee83e12b55b",
    "outputId": "fae2ffc8-5a11-4a24-9b48-675ef0d25158"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176d482f231d4f20b408e66da9a7d588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='best_lyra_model_Regression_RNA_20250423_043613.pt', description='Model File:', styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Use trained model to predict new data\n",
    "from google.colab import files\n",
    "\n",
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load the saved model and get its configuration\"\"\"\n",
    "    global task_type  # Use the global task_type variable\n",
    "\n",
    "    checkpoint = torch.load(model_path)\n",
    "    sequence_type = checkpoint['sequence_type']\n",
    "\n",
    "    # Get encoder and initialize model\n",
    "    _, encoder, d_input = setup_sequence_model(sequence_type)\n",
    "    global d_output\n",
    "    model = Lyra(d_input=d_input, d_output=d_output, d_model=64).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    print(f\"Model loaded successfully! Sequence type: {sequence_type}, Task type: {task_type}\")\n",
    "    return model, encoder\n",
    "\n",
    "def predict_sequences(model_path, input_path, output_path, batch_size=64):\n",
    "    \"\"\"Make predictions and save to output file\"\"\"\n",
    "    global task_type  # Use the global task_type variable\n",
    "\n",
    "    # Load model\n",
    "    model, encoder = load_model(model_path)\n",
    "    model.eval()\n",
    "\n",
    "    # Load input data\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Encode sequences\n",
    "    encoded_seqs = encoder(df['seq'].values)\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = PredictionDataset(encoded_seqs)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Make predictions in batches\n",
    "    predictions = []\n",
    "    scores = []  # For classification probabilities\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Making predictions'):\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "\n",
    "            if task_type == 'Classification':\n",
    "                # Handle both binary and multiclass classification\n",
    "                if d_output == 1:  # Binary classification\n",
    "                    # Get probabilities for binary classification\n",
    "                    probs = torch.sigmoid(outputs)\n",
    "                    scores.append(probs.cpu().numpy())\n",
    "                    # Convert to binary predictions\n",
    "                    preds = (probs > 0.5).float()\n",
    "                else:  # Multiclass classification\n",
    "                    # Get probabilities using softmax for multiclass\n",
    "                    probs = torch.softmax(outputs, dim=1)\n",
    "                    scores.append(probs.cpu().numpy())\n",
    "                    # Get class with highest probability\n",
    "                    preds = torch.argmax(probs, dim=1)\n",
    "                predictions.append(preds.cpu().numpy())\n",
    "            else:\n",
    "                # For regression, use outputs directly\n",
    "                predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    predictions = np.concatenate(predictions)\n",
    "\n",
    "    # Save predictions\n",
    "    df['prediction'] = predictions\n",
    "\n",
    "    # Add probability scores for classification\n",
    "    if task_type == 'Classification':\n",
    "        scores = np.concatenate(scores)\n",
    "        if d_output == 1:  # Binary classification\n",
    "            df['probability'] = scores\n",
    "        else:  # Multiclass classification\n",
    "            # Add probability for each class\n",
    "            for i in range(d_output):\n",
    "                df[f'probability_class_{i}'] = scores[:, i]\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Trigger download\n",
    "    files.download(output_path)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Create and display the form\n",
    "model_file = widgets.Text(\n",
    "    value=model_name,\n",
    "    description='Model File:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "input_file = widgets.Text(\n",
    "    value='test.csv',\n",
    "    description='Input File:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "output_file = widgets.Text(\n",
    "    value='predictions.csv',\n",
    "    description='Output File:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "predict_button = widgets.Button(description=\"Make Predictions\")\n",
    "\n",
    "def on_button_click(b):\n",
    "    try:\n",
    "        predictions = predict_sequences(model_file.value, input_file.value, output_file.value)\n",
    "        print(f\"\\nPredictions completed successfully!\")\n",
    "        print(f\"Results saved to: {output_file.value}\")\n",
    "        print(f\"Number of predictions: {len(predictions)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "\n",
    "predict_button.on_click(on_button_click)\n",
    "\n",
    "form = widgets.VBox([model_file, input_file, output_file, predict_button])\n",
    "display(form)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12f1342c560e4f69b0e1a3fd7a14d32c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "176d482f231d4f20b408e66da9a7d588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_da4ad9e2a06e433dad0255452ad9d011",
       "IPY_MODEL_930be6577c3e41ab9ed9547afa2dc07a",
       "IPY_MODEL_bef25abf18e34bdebfab53e2eb4e48ed",
       "IPY_MODEL_d18549085fd2499281a0b0500d47df95"
      ],
      "layout": "IPY_MODEL_fdb8d963015a47b29b5049c97ec4d544"
     }
    },
    "22a56abe26aa4605a2b9f0be9fa8354a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Initialize Task",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_c5eb03f30eea4c4ca92bf77a8544d661",
      "style": "IPY_MODEL_380b6f8caab442a298c752324a204d0c",
      "tooltip": ""
     }
    },
    "2cbc054083e34a0b83a05d6f679d1cce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dd4298ecc5241c082931b7226c414f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "321e074458124a709b75018731cefc09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c922fcc587114447a895b3ca3e52c38d",
       "IPY_MODEL_3943a6b618e44446a69e2bec839810f9",
       "IPY_MODEL_b10ecc2d068e4913ac79e57f9bfcf31f",
       "IPY_MODEL_b870ea7feadc4250b364434971462447",
       "IPY_MODEL_8dd20fa905964e289b0801a6456d1d09",
       "IPY_MODEL_8b9920c695004aae8fc03d4e493690aa",
       "IPY_MODEL_5859f44352724c998a8a8bc1d2506c11",
       "IPY_MODEL_22a56abe26aa4605a2b9f0be9fa8354a"
      ],
      "layout": "IPY_MODEL_2dd4298ecc5241c082931b7226c414f1"
     }
    },
    "34aeb16e679d438c962330b3dc7f0a79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "3604eec120694a5f842117483be553e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36ee6e0c98ae4f3896d2196aaf3043c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "380b6f8caab442a298c752324a204d0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "3943a6b618e44446a69e2bec839810f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "Regression",
       "Classification"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Task Type:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_b959111367674f8ca7e91e9019893ba5",
      "style": "IPY_MODEL_dc23fafe86084d4baacde13f0f43df4f"
     }
    },
    "39de001a0d4d4fe287b11913890e354b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "3c4e15f2539a45a886d95039e3bf1eb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "4124d4888ef14e62976e79bcec2bdf33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ee3454d820840eaa674f6bbef669e25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5859f44352724c998a8a8bc1d2506c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Label Column Name:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_5f4f0f881af742548453d167a0e9135f",
      "placeholder": "​",
      "style": "IPY_MODEL_70f015f1e9f84a16a9a6ba69a1e6d099",
      "value": "proximal_isoform_proportion"
     }
    },
    "5f4f0f881af742548453d167a0e9135f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68a81239a5324a2989ceed671cdf7ce6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70f015f1e9f84a16a9a6ba69a1e6d099": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "7ed0d072c3bf4ae7a34333751c23322e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b9920c695004aae8fc03d4e493690aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Testing Data File:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_7ed0d072c3bf4ae7a34333751c23322e",
      "placeholder": "​",
      "style": "IPY_MODEL_9bc72e101e1f4203a732d7844a83634d",
      "value": "test.csv"
     }
    },
    "8dd20fa905964e289b0801a6456d1d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Validation Data File:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_9122a6de18c24d588e912331f9de74ac",
      "placeholder": "​",
      "style": "IPY_MODEL_36ee6e0c98ae4f3896d2196aaf3043c3",
      "value": "val.csv"
     }
    },
    "9122a6de18c24d588e912331f9de74ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "930be6577c3e41ab9ed9547afa2dc07a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Input File:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_bdeb409071e34b3d9537c47cd6187c66",
      "placeholder": "​",
      "style": "IPY_MODEL_94378188bd324da09e3692ca6b54a94e",
      "value": "test.csv"
     }
    },
    "94378188bd324da09e3692ca6b54a94e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "960e5b9fc6094619be1f894293083719": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "9bc72e101e1f4203a732d7844a83634d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "b10ecc2d068e4913ac79e57f9bfcf31f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntTextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntTextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntTextView",
      "continuous_update": false,
      "description": "Number of Classes:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_960e5b9fc6094619be1f894293083719",
      "step": 1,
      "style": "IPY_MODEL_39de001a0d4d4fe287b11913890e354b",
      "value": 2
     }
    },
    "b870ea7feadc4250b364434971462447": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Training Data File:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_68a81239a5324a2989ceed671cdf7ce6",
      "placeholder": "​",
      "style": "IPY_MODEL_3c4e15f2539a45a886d95039e3bf1eb6",
      "value": "train.csv"
     }
    },
    "b959111367674f8ca7e91e9019893ba5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdeb409071e34b3d9537c47cd6187c66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bef25abf18e34bdebfab53e2eb4e48ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Output File:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_3604eec120694a5f842117483be553e1",
      "placeholder": "​",
      "style": "IPY_MODEL_12f1342c560e4f69b0e1a3fd7a14d32c",
      "value": "predictions.csv"
     }
    },
    "c5eb03f30eea4c4ca92bf77a8544d661": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c922fcc587114447a895b3ca3e52c38d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "RNA",
       "DNA",
       "Protein"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Sequence Type:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_4124d4888ef14e62976e79bcec2bdf33",
      "style": "IPY_MODEL_e1efdef9aacc453dab82e2a008a3814e"
     }
    },
    "d18549085fd2499281a0b0500d47df95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Make Predictions",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_2cbc054083e34a0b83a05d6f679d1cce",
      "style": "IPY_MODEL_ec8cfc6604a849458cacbcd5725cd022",
      "tooltip": ""
     }
    },
    "da4ad9e2a06e433dad0255452ad9d011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Model File:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_4ee3454d820840eaa674f6bbef669e25",
      "placeholder": "​",
      "style": "IPY_MODEL_34aeb16e679d438c962330b3dc7f0a79",
      "value": "best_lyra_model_Regression_RNA_20250423_043613.pt"
     }
    },
    "dc23fafe86084d4baacde13f0f43df4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "e1efdef9aacc453dab82e2a008a3814e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "ec8cfc6604a849458cacbcd5725cd022": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "fdb8d963015a47b29b5049c97ec4d544": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
